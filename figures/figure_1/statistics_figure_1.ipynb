{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3f8bac-5db0-43c4-a873-666e9feebd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import wilcoxon,ranksums,mannwhitneyu\n",
    "# load the source data for each panel \n",
    "panel_b = pd.read_excel('./fig1_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_b',index_col=0)\n",
    "panel_c = pd.read_excel('./fig1_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_c',index_col=0)\n",
    "panel_d = pd.read_excel('./fig1_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_d',index_col=0)\n",
    "panel_e = pd.read_excel('./fig1_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_e',index_col=0)\n",
    "panel_f = pd.read_excel('./fig1_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_f',index_col=0)\n",
    "panel_g = pd.read_excel('./fig1_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_g',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555c0ae7-278e-4665-8a67-8a53f46c8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def bootstrap(arr,itr=20000):\n",
    "    boots = []\n",
    "    for i in range(itr):\n",
    "        boots.append(np.median(np.random.choice(arr,arr.shape,replace=True)))\n",
    "        \n",
    "    return(boots)\n",
    "\n",
    "def print_bootstrap_results(df,metric,lang,itr=20000):\n",
    "    to_use = df[(df.Metric == metric) & (df.lang == lang)]['WER']\n",
    "    #to_use = df[(df.paradigm == metric) & (df.lang == lang)]['WER']\n",
    "        \n",
    "    straps = np.array(bootstrap(to_use))\n",
    "    median_value = np.round(np.median(to_use),2)\n",
    "    low_bound = np.round(np.percentile(straps,0.5),2)\n",
    "    up_bound = np.round(np.percentile(straps,99.5),2)\n",
    "    print('Results for: ',metric, ' ', lang)\n",
    "    print('Median: ', median_value)\n",
    "    print('99% CI: [', low_bound, ', ', up_bound, ']')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f58e4d-f143-46ee-a6b2-ff26758bd3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WER</th>\n",
       "      <th>lang</th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.888889</td>\n",
       "      <td>english</td>\n",
       "      <td>Real-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.222222</td>\n",
       "      <td>english</td>\n",
       "      <td>Real-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>english</td>\n",
       "      <td>Real-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.666667</td>\n",
       "      <td>english</td>\n",
       "      <td>Real-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>english</td>\n",
       "      <td>Real-time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WER     lang     Metric\n",
       "0  38.888889  english  Real-time\n",
       "1  22.222222  english  Real-time\n",
       "2  20.000000  english  Real-time\n",
       "3   6.666667  english  Real-time\n",
       "4   0.000000  english  Real-time"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb2a57e-61d4-4856-b63d-19337498143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  Real-time   overall\n",
      "Median:  25.0\n",
      "99% CI: [ 17.24 ,  36.36 ]\n",
      "\n",
      "Results for:  Real-time   english\n",
      "Median:  22.22\n",
      "99% CI: [ 7.14 ,  43.75 ]\n",
      "\n",
      "Results for:  Real-time   spanish\n",
      "Median:  26.67\n",
      "99% CI: [ 18.18 ,  33.33 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_bootstrap_results(panel_b,'Real-time','overall')\n",
    "print_bootstrap_results(panel_b,'Real-time','english')\n",
    "print_bootstrap_results(panel_b,'Real-time','spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f080ef18-418f-419f-a358-9ff5832eb288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  Neural-only   overall\n",
      "Median:  70.62\n",
      "99% CI: [ 61.88 ,  78.12 ]\n",
      "\n",
      "Results for:  Neural-only   english\n",
      "Median:  55.0\n",
      "99% CI: [ 46.25 ,  68.75 ]\n",
      "\n",
      "Results for:  Neural-only   spanish\n",
      "Median:  52.5\n",
      "99% CI: [ 40.42 ,  61.67 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_bootstrap_results(panel_b,'Neural-only','overall')\n",
    "print_bootstrap_results(panel_b,'Neural-only','english')\n",
    "print_bootstrap_results(panel_b,'Neural-only','spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ea2792-af63-43fc-a74c-db5cb19ef582",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Language': [], 'Paradigm 1': [], 'Paradigm 2': [], 'Test-statistic': [], 'P-value': []} \n",
    "compares = [('Chance','Neural-only'),('Chance','Real-time'),('Neural-only','Real-time')]\n",
    "langs = ['overall','spanish','english']\n",
    "all_ps = []\n",
    "for lang in langs:\n",
    "    for compare in compares:\n",
    "        d['Language'].append(lang.capitalize())\n",
    "        d['Paradigm 1'].append(compare[0])\n",
    "        d['Paradigm 2'].append(compare[1])\n",
    "    \n",
    "        result = mannwhitneyu(panel_b['WER'][(panel_b['lang'] == lang) & (panel_b['Metric'] == compare[0])],\n",
    "                 panel_b['WER'][(panel_b['lang'] == lang) & (panel_b['Metric'] == compare[1])])\n",
    "        d['Test-statistic'].append(result[0])\n",
    "        d['P-value'].append(result[1])\n",
    "\n",
    "d = pd.DataFrame(d)\n",
    "d['P-value'] = multipletests(d['P-value'].values,alpha=0.01,method='holm')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c404847-f19f-4cf7-8574-8fdb00a1c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      "Language &  Paradigm 1 &  Paradigm 2 &  Test-statistic &  P-value \\\\\n",
      "\\midrule\n",
      " Overall &      Chance & Neural-only &        4.41e+02 & 1.91e-07 \\\\\n",
      " Overall &      Chance &   Real-time &        4.41e+02 & 1.91e-07 \\\\\n",
      " Overall & Neural-only &   Real-time &        4.40e+02 & 1.91e-07 \\\\\n",
      " Spanish &      Chance & Neural-only &        4.41e+02 & 1.91e-07 \\\\\n",
      " Spanish &      Chance &   Real-time &        4.41e+02 & 1.91e-07 \\\\\n",
      " Spanish & Neural-only &   Real-time &        4.13e+02 & 2.66e-06 \\\\\n",
      " English &      Chance & Neural-only &        4.40e+02 & 1.91e-07 \\\\\n",
      " English &      Chance &   Real-time &        4.41e+02 & 1.91e-07 \\\\\n",
      " English & Neural-only &   Real-time &        3.74e+02 & 1.24e-04 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3142015/3706759632.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(d.to_latex(index=False,float_format=\"{:0.2e}\".format))\n"
     ]
    }
   ],
   "source": [
    "print(d.to_latex(index=False,float_format=\"{:0.2e}\".format))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70760269-922b-45e0-ae94-65984b23bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  Real-time\n",
      "Median:  87.5\n",
      "99% CI: [ 85.71 ,  100.0 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_use = panel_c[panel_c.paradigm == 'Real-time'].Acc\n",
    "straps = np.array(bootstrap(to_use))\n",
    "median_value = np.round(np.median(to_use),2)\n",
    "low_bound = np.round(np.percentile(straps,0.5),2)\n",
    "up_bound = np.round(np.percentile(straps,99.5),2)\n",
    "print('Results for: ','Real-time')\n",
    "print('Median: ', median_value)\n",
    "print('99% CI: [', low_bound, ', ', up_bound, ']')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea89132d-4287-4e5e-a0fe-80ef0f00c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Evaluation 1': [], 'Evaluation 2': [], 'Test-statistic': [], 'P-value': []} \n",
    "compares = [('Chance','Neural-only'),('Chance','Real-time'),('Neural-only','Real-time')]\n",
    "\n",
    "for compare in compares:\n",
    "    d['Evaluation 1'].append(compare[0])\n",
    "    d['Evaluation 2'].append(compare[1])\n",
    "\n",
    "    result = mannwhitneyu(panel_c['Acc'][(panel_c['paradigm'] == compare[0])],\n",
    "             panel_c['Acc'][(panel_c['paradigm'] == compare[1])])\n",
    "    d['Test-statistic'].append(result[0])\n",
    "    d['P-value'].append(result[1])\n",
    "\n",
    "d = pd.DataFrame(d)\n",
    "d['P-value'] = multipletests(d['P-value'].values,alpha=0.01,method='holm')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57afe5bf-40ff-4dab-b828-e23c2dbf0e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "Evaluation 1 & Evaluation 2 &  Test-statistic &  P-value \\\\\n",
      "\\midrule\n",
      "      Chance &  Neural-only &        1.05e+02 & 4.79e-03 \\\\\n",
      "      Chance &    Real-time &        1.50e+01 & 5.44e-07 \\\\\n",
      " Neural-only &    Real-time &        1.02e+02 & 4.79e-03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3142015/3706759632.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(d.to_latex(index=False,float_format=\"{:0.2e}\".format))\n"
     ]
    }
   ],
   "source": [
    "print(d.to_latex(index=False,float_format=\"{:0.2e}\".format))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8186a4e-6d7d-4be0-9ce8-2180ff47bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  Real-time   overall\n",
      "Median:  21.88\n",
      "99% CI: [ 16.67 ,  27.59 ]\n",
      "\n",
      "Results for:  Real-time   english\n",
      "Median:  20.0\n",
      "99% CI: [ 6.67 ,  33.33 ]\n",
      "\n",
      "Results for:  Real-time   spanish\n",
      "Median:  20.0\n",
      "99% CI: [ 16.67 ,  28.57 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_bootstrap_results(panel_g,'Real-time','overall')\n",
    "print_bootstrap_results(panel_g,'Real-time','english')\n",
    "print_bootstrap_results(panel_g,'Real-time','spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf3a76d-6413-48f5-8a14-da768fe180d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Language': [], 'Paradigm 1': [], 'Paradigm 2': [], 'Test-statistic': [], 'P-value': []} \n",
    "compares = [('Chance','Real-time')]\n",
    "langs = ['overall','spanish','english']\n",
    "all_ps = []\n",
    "for lang in langs:\n",
    "    for compare in compares:\n",
    "        d['Language'].append(lang)\n",
    "        d['Paradigm 1'].append(compare[0])\n",
    "        d['Paradigm 2'].append(compare[1])\n",
    "    \n",
    "        result = mannwhitneyu(panel_g['WER'][(panel_g['lang'] == lang) & (panel_g['Metric'] == compare[0])],\n",
    "                 panel_g['WER'][(panel_g['lang'] == lang) & (panel_g['Metric'] == compare[1])])\n",
    "        d['Test-statistic'].append(result[0])\n",
    "        d['P-value'].append(result[1])\n",
    "\n",
    "d = pd.DataFrame(d)\n",
    "d['P-value'] = multipletests(d['P-value'].values,alpha=0.01,method='holm')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a7ee21-425f-48ec-b494-cc258bf9b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      "Language & Paradigm 1 & Paradigm 2 &  Test-statistic &  P-value \\\\\n",
      "\\midrule\n",
      " overall &     Chance &  Real-time &        4.41e+02 & 6.41e-08 \\\\\n",
      " spanish &     Chance &  Real-time &        4.41e+02 & 6.41e-08 \\\\\n",
      " english &     Chance &  Real-time &        4.41e+02 & 6.41e-08 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3142015/3706759632.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(d.to_latex(index=False,float_format=\"{:0.2e}\".format))\n"
     ]
    }
   ],
   "source": [
    "print(d.to_latex(index=False,float_format=\"{:0.2e}\".format))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8050cf94-e8ae-4f9b-83b2-b74a4cf23256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>target-lang</th>\n",
       "      <th>correct_decode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.206533</td>\n",
       "      <td>Target language</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.629613</td>\n",
       "      <td>Off-target language</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.648934</td>\n",
       "      <td>Off-target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.662223</td>\n",
       "      <td>Target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599495</td>\n",
       "      <td>Target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.662223</td>\n",
       "      <td>Target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.475434</td>\n",
       "      <td>Target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.611038</td>\n",
       "      <td>Off-target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Off-target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.297847</td>\n",
       "      <td>Target language</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score          target-lang  correct_decode\n",
       "0    0.206533      Target language           False\n",
       "1    0.629613  Off-target language           False\n",
       "2    0.648934  Off-target language            True\n",
       "3    0.662223      Target language            True\n",
       "4    0.599495      Target language            True\n",
       "..        ...                  ...             ...\n",
       "267  0.662223      Target language            True\n",
       "268  0.475434      Target language            True\n",
       "269  0.611038  Off-target language            True\n",
       "270  0.000000  Off-target language            True\n",
       "271  0.297847      Target language            True\n",
       "\n",
       "[272 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ac0ac46-0cf9-4ed5-a602-f406733cc030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3142015/304959185.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mannwhitneyu(panel_f[np.logical_not(panel_f['correct_decode'])][panel_f['target-lang'] == 'Target language'].score.values,\n",
      "/tmp/ipykernel_3142015/304959185.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  panel_f[np.logical_not(panel_f['correct_decode'])][panel_f['target-lang'] == 'Off-target language'].score.values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=60.0, pvalue=0.5066281058229414)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target vs off target language scores for INCORRECT decodes\n",
    "\n",
    "\n",
    "mannwhitneyu(panel_f[np.logical_not(panel_f['correct_decode'])][panel_f['target-lang'] == 'Target language'].score.values,\n",
    "             panel_f[np.logical_not(panel_f['correct_decode'])][panel_f['target-lang'] == 'Off-target language'].score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e98c8807-6c7f-4d9f-9385-c67782fd7fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3142015/4183134976.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mannwhitneyu(panel_f[panel_f['correct_decode']][panel_f['target-lang'] == 'Target language'].score.values,\n",
      "/tmp/ipykernel_3142015/4183134976.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  panel_f[panel_f['correct_decode']][panel_f['target-lang'] == 'Off-target language'].score.values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=11177.5, pvalue=6.533119893582141e-10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target vs off target language scores for CORRECT decodes\n",
    "\n",
    "mannwhitneyu(panel_f[panel_f['correct_decode']][panel_f['target-lang'] == 'Target language'].score.values,\n",
    "             panel_f[panel_f['correct_decode']][panel_f['target-lang'] == 'Off-target language'].score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0f9c3-dc19-48f2-bfd0-da637114356e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
